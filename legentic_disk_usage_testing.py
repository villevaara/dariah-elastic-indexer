from smart_open import open
from elasticsearch import Elasticsearch, helpers
import json
from lib.utils import read_elastic_pwd, log_line, read_indexed_log, get_id_from_str
import argparse
from threading import Thread
from threading import Lock
import queue
from tqdm import tqdm


def get_allas_url_ndjson(allas_url, add_id=True):
    with open(allas_url, encoding='utf-8') as rawfile:
        rawdata = rawfile.read()
        jsondata = json.loads(rawdata)
        docs = jsondata['documents']
        retdocs = list()
        for doc in docs:
            thisdoc = doc['fields']
            if add_id:
                thisdoc['_id'] = get_id_from_str(
                    doc['fields']['url'].replace("https://", "").replace("http://", "").replace("/", "_").replace(":", ""))
            retdocs.append(thisdoc)
    return retdocs


# assign new keys for fields to be remapped
def remap_inputdata(inputdata, remapping):
    remapped_data = dict()
    for k, v in inputdata.items():
        if k in remapping.keys():
            remapped_data[remapping[k]] = v
        else:
            remapped_data[k] = v
    return remapped_data


# 'version' field caused problems in indexing. Discard for now.
def fix_version_field(input_item):
    # input_item['version'] = "_" + "-".join(input_item['version'])
    del input_item['version']


# apply remapping field names and fix other problematic fields for bulk indexing
def remap_bulk_batch(items_batch, remappings, fix_version=True):
    remapped = list()
    for item in items_batch:
        new_item = remap_inputdata(item, remappings)
        if fix_version:
            fix_version_field(new_item)
        remapped.append(new_item)
    return remapped


# read filelist, append to ALLAS url. These are the data files on ALLAS.
allas_url = 'https://a3s.fi/'
with open('../dariah-elastic-data/legentic_files.txt', 'r') as txtfile:
    allas_items = [allas_url + item.strip() for item in txtfile.readlines()]

# read dictionary to remap field names. Some caused trouble in indexing.
# see legentic_indexer.py for how the remappings were done.
with open('data/legentic_remappings.json', 'r') as jsonfile:
    remappings = json.load(jsonfile)


# Password for the 'elastic' user generated by Elasticsearch
ELASTIC_PASSWORD = read_elastic_pwd("./secrets.txt")
# Create the client instance
# test env client
client = Elasticsearch("https://ds-es-dev.rahtiapp.fi:443",
                       basic_auth=("elastic", ELASTIC_PASSWORD), request_timeout=60)

mapping = {
    "properties": {
        'indexed': {"type": "date", "format": "yyyy-MM-dd HH:mm:ss Z"},
        'published': {"type": "date", "format": "yyyy-MM-dd HH:mm:ss Z"},
        'author.name': {"type": "text"},
        'author.text.hashtag': {"type": "keyword"},
        'author.text.user_mention': {"type": "keyword"},
        'author.text.content': {"type": "keyword"},
        'author.content': {"type": "keyword"},
        'author-uri': {"type": "keyword"},
        'author-community_facebook': {"type": "keyword"},
        'author-id_facebook': {"type": "keyword"},
        'author-following': {"type": "integer"},
        'author-followers': {"type": "integer"},
        'blog_id': {"type": "keyword"},
        'citation.length': {"type": "integer"},
        'citation.content': {"type": "keyword"},
        'description.content': {"type": "text"},
        'facebook_id': {"type": "keyword"},
        'forum_post_id': {"type": "keyword"},
        'google-id': {"type": "keyword"},
        'instagram-author-id': {"type": "keyword"},
        'instagram-ref-author-id': {"type": "keyword"},
        'language': {"type": "keyword"},
        'latency': {"type": "long"},
        'latitude': {"type": "float"},
        'longitude': {"type": "float"},
        'name.content': {"type": "text"},
        'page-title.content': {"type": "text"},
        'quote.content': {"type": "text"},
        'type': {"type": "keyword"},
        'url': {"type": "keyword"},
        'ref-author': {"type": "text"},
        'ref-author-id_facebook': {"type": "keyword"},
        'ref-author-uri': {"type": "keyword"},
        'subject.content': {"type": "keyword"},
        'subject.length': {"type": "integer"},
        'text.address.size': {"type": "integer"},
        'text.content': {"type": "text"},
        'text.email.size': {"type": "integer"},
        'text.hashtag': {"type": "keyword"},
        'text.person.content': {"type": "keyword"},
        'text.person.size': {"type": "integer"},
        'text.phone.canonized': {"type": "keyword"},
        'text.phone.content': {"type": "text"},
        'text.url.content': {"type": "text"},
        'text.url.length': {"type": "integer"},
        'text.user_mention': {"type": "keyword"},
        'thread.title.content': {"type": "text"},
        'twitter_retweet_id': {"type": "keyword"},
        'twitter_tweet_id': {"type": "keyword"},
        'youtube-channel-id': {"type": "keyword"},
    }
}

mapping_no_source = {
    "_source": {"enabled": False},
    "properties": {
        'indexed': {"type": "date", "format": "yyyy-MM-dd HH:mm:ss Z"},
        'published': {"type": "date", "format": "yyyy-MM-dd HH:mm:ss Z"},
        'author.name': {"type": "text"},
        'author.text.hashtag': {"type": "keyword"},
        'author.text.user_mention': {"type": "keyword"},
        'author.text.content': {"type": "keyword"},
        'author.content': {"type": "keyword"},
        'author-uri': {"type": "keyword"},
        'author-community_facebook': {"type": "keyword"},
        'author-id_facebook': {"type": "keyword"},
        'author-following': {"type": "integer"},
        'author-followers': {"type": "integer"},
        'blog_id': {"type": "keyword"},
        'citation.length': {"type": "integer"},
        'citation.content': {"type": "keyword"},
        'description.content': {"type": "text"},
        'facebook_id': {"type": "keyword"},
        'forum_post_id': {"type": "keyword"},
        'google-id': {"type": "keyword"},
        'instagram-author-id': {"type": "keyword"},
        'instagram-ref-author-id': {"type": "keyword"},
        'language': {"type": "keyword"},
        'latency': {"type": "long"},
        'latitude': {"type": "float"},
        'longitude': {"type": "float"},
        'name.content': {"type": "text"},
        'page-title.content': {"type": "text"},
        'quote.content': {"type": "text"},
        'type': {"type": "keyword"},
        'url': {"type": "keyword"},
        'ref-author': {"type": "text"},
        'ref-author-id_facebook': {"type": "keyword"},
        'ref-author-uri': {"type": "keyword"},
        'subject.content': {"type": "keyword"},
        'subject.length': {"type": "integer"},
        'text.address.size': {"type": "integer"},
        'text.content': {"type": "text"},
        'text.email.size': {"type": "integer"},
        'text.hashtag': {"type": "keyword"},
        'text.person.content': {"type": "keyword"},
        'text.person.size': {"type": "integer"},
        'text.phone.canonized': {"type": "keyword"},
        'text.phone.content': {"type": "text"},
        'text.url.content': {"type": "text"},
        'text.url.length': {"type": "integer"},
        'text.user_mention': {"type": "keyword"},
        'thread.title.content': {"type": "text"},
        'twitter_retweet_id': {"type": "keyword"},
        'twitter_tweet_id': {"type": "keyword"},
        'youtube-channel-id': {"type": "keyword"},
    }
}

index_settings = {
    'number_of_shards': 1,
}

index_settings_best_c = {
    'number_of_shards': 1,
    'codec': 'best_compression'
}

index_settings_no_source = {
    'number_of_shards': 1,
    'soft_deletes.enabled': False
}

# standard
index_name = "legentic-standard"
client.indices.delete(index=index_name)
client.indices.create(index=index_name, mappings=mapping, settings=index_settings)
for item in tqdm(allas_items[:5]):
    inputdata = get_allas_url_ndjson(allas_url=item, add_id=True)
    input_remapped = remap_bulk_batch(items_batch=inputdata, remappings=remappings, fix_version=True)
    helpers.bulk(client, input_remapped, index=index_name)

client.indices.get_settings(index=index_name) # check current settings
client.indices.close(index=index_name) # index needs to be closed for codec setting to be changeable
client.indices.put_settings(index=index_name, settings={'codec': 'best_compression'})
client.indices.open(index=index_name)
client.indices.forcemerge(index=index_name)

# no-source
index_name = "legentic-no-source"
client.indices.delete(index=index_name)
client.indices.create(index=index_name, mappings=mapping_no_source, settings=index_settings_no_source)
for item in tqdm(allas_items[:5]):
    inputdata = get_allas_url_ndjson(allas_url=item, add_id=True)
    input_remapped = remap_bulk_batch(items_batch=inputdata, remappings=remappings, fix_version=True)
    helpers.bulk(client, input_remapped, index=index_name)

# best-compression
index_name = "legentic-best-compression"
client.indices.delete(index=index_name)
client.indices.create(index=index_name, mappings=mapping, settings=index_settings_best_c)
for item in tqdm(allas_items[:5]):
    inputdata = get_allas_url_ndjson(allas_url=item, add_id=True)
    input_remapped = remap_bulk_batch(items_batch=inputdata, remappings=remappings, fix_version=True)
    helpers.bulk(client, input_remapped, index=index_name)

# # create the index if it doesn't exist
# # client.indices.delete(index=index_name)
# client.indices.create(index=index_name, mappings=mapping, settings=index_settings)
# # deleting an index
#
# inputdata = get_allas_url_ndjson(allas_url=allas_items[0], add_id=True)
# input_remapped = remap_bulk_batch(items_batch=inputdata, remappings=remappings, fix_version=True)
# helpers.bulk(client, input_remapped, index=index_name)
#
#
