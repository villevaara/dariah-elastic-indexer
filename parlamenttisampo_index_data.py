from datetime import datetime
from elasticsearch import Elasticsearch, helpers
from glob import glob
import json
import ndjson
from datetime import datetime
from tqdm import tqdm
from lib.utils import read_elastic_pwd


def reshape_data(data_entry):
    reshaped = dict()
    for k in data_entry.keys():
        v = data_entry[k]
        if k == "version":
            k = "doc_version"
        if v == "" or v is None:
            v = None
        else:
            if k in ['start_time', 'end_time']:
                t_h = v.split('.')[0]
                if len(t_h) == 1:
                    t_h = "0" + t_h
                t_m = v.split('.')[-1] 
                if len(t_m) == 1:
                    t_m = t_m + "0"
                t_t = t_h + ":" + t_m
                if t_t == "24:00":
                    t_t = "23:59"
                if len(t_t) != 5:
                    v = None
                elif not t_h.isdigit() or not t_m.isdigit():
                    v = None
                elif int(t_h) > 24 or int(t_m) > 59:
                    v = None
                else:
                    v = data_entry['date'] + " " + t_t
            if k in ['speech_start', 'speech_end']:
                if len(v) == 19:
                    v = v.replace("T", " ")
        reshaped[k] = v
    return reshaped


def read_ndjson(ndjson_file):
    retlist = list()
    with open(ndjson_file, 'r') as jsonfile:
        data = ndjson.load(jsonfile)
    for item in data:
        retlist.append(reshape_data(item))
    return retlist


def add_bulk_values(inputdata):
    for item in inputdata:
        item['_id'] = item['speech_id'].replace("_", "-")
        # item['_op_type'] = 'index' ## this is the default value
    return inputdata


# Password for the 'elastic' user generated by Elasticsearch
ELASTIC_PASSWORD = read_elastic_pwd("./secrets.txt")
# Create the client instance
client = Elasticsearch("https://ds-es.rahtiapp.fi:443",
                       basic_auth=("elastic", ELASTIC_PASSWORD), request_timeout=60)


mapping = {
    "properties": {
        "speech_id": {"type": "keyword"},
        "session": {"type": "keyword"},
        "date": {"type": "date", "format": "yyyy-MM-dd"},
        "start_time": {"type": "date", "format": "yyyy-MM-dd HH:mm"},
        "end_time": {"type": "date", "format": "yyyy-MM-dd HH:mm"},
        "given": {"type": "keyword"},
        "family": {"type": "keyword"},
        "role": {"type": "keyword"},
        "party": {"type": "keyword"},
        "topic": {"type": "text"},
        "content": {"type": "text"},
        "speech_type": {"type": "keyword"},
        "mp_uri": {"type": "keyword"},
        "gender": {"type": "keyword"},
        "birth": {"type": "date", "format": "yyyy-MM-dd"},
        "party_uri": {"type": "keyword"},
        "parliamentary_role": {"type": "keyword"},
        "group_uri": {"type": "keyword"},
        "link": {"type": "keyword"},
        "lang": {"type": "keyword"},
        "name_in_source": {"type": "text"},
        "page": {"type": "integer"},
        "speaker_id": {"type": "keyword"},
        'speech_start': {"type": "date", "format": "yyyy-MM-dd HH:mm:ss"},
        'speech_end': {"type": "date", "format": "yyyy-MM-dd HH:mm:ss"},
        'speech_status': {"type": "keyword"},
        'speech_version': {"type": "keyword"},
        'doc_version': {"type": "keyword"},
        'status': {"type": "keyword"},
    }
}


index_name = "parlamenttisampo"
# create the index if it doesn't exist
# client.indices.create(index=index_name, mappings=mapping)

# read data
data_json = glob("../dariah-elastic-data/work/parlamenttisampo/*.ndjson")

# index doc range, one document at a time - for testing, this gives more detailed error messages than the bulk API
# test_data = read_ndjson(data_json[859])
# for i in range(0, 1000):
#     doc = test_data[i]
#     resp = client.index(index=index_name, id=doc["speech_id"].replace("_", "-"), document=doc)
#     print(str(i) + " " + resp['result'])


# index bulk - updates if id already present.
for ndjson_file in tqdm(data_json):
    # print(ndjson_file)
    inputdata = read_ndjson(ndjson_file)
    inputdata = add_bulk_values(inputdata)
    helpers.bulk(client, inputdata, index=index_name)
